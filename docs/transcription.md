# Leveling Up with AI - Talk Transcription

Transcribed from informal walkthrough recording. This was a conversational presentation where Craig walked through the slides with a friend, demonstrating tools and discussing concepts in real-time.

---

## Section: Introduction - The Widening Gulf

### Slide 1: The Widening Gulf of Technology

> The general idea is that, with any technology, I see it as a tool. If you have a bike, you can do things that people without bikes can't do. If you have the internet, you can do things that people without the internet can't do. And as the tools get more powerful, the people who are using them have more abilities and can do things faster than people who can't. And I think AI is just moving so quickly, it is an ever-widening kind of chasm.

### Slide 6: What It Takes

> What it means to be technical is changing. It used to be that you had to be able to code -- you had front-end engineers and back-end engineers. And now the line of what it means to be technical is kind of amorphous. So it's really like, what are you willing to learn? Because you have this ever-present thing that can break things down, build things, teach you -- that sort of thing.

### Slide 2: Mental Models Through Use

> I have a mental model of how Google works. So if I give a problem to my parents and I'm like, okay, use Google and figure out the directions to this ice cream shop, they can get there. But they might also look for their friend's photos that are on Facebook -- they might look on Google, because they don't have a model of how Google works. Through using Google, you're like, obviously, that's not going to work. But for people who are like, "Well, there are photos around the internet. Why can't I get them through Google?" -- that's a completely logical question, because their mental model is not correct.
>
> In the same way that you improve just by using Google, the same thing is true here. You don't need to read an instruction manual, you just have to use this stuff a whole bunch.

---

## Section: Understanding AI

### Slide 3: New Tech, Old Mental Model

> There's a temptation to use ChatGPT just like Google -- it's a better version of Google, it gives me answers, we're walking through things. But it's not really like Google at all in its inherent nature. Google has certain flaws, like it has borders of what you can't cross into, like private websites. And then ChatGPT has things like hallucinations.
>
> You really want to figure out a mental map of what these tools are capable of. And the better your mental map, the more you can use them.

### Slide 4: From Savant to Digital Employee

> The big jump is going from it just being something where you're asking questions and getting text answers back, to it actually doing actual work. Moving to Claude Code is an example of that. But there are also a lot of other examples that are kind of prior to that. A lot of people get stuck at the chat stage.

---

## Section: Mapping the Journey

### Slide 5: Mapping the Journey

> The idea of the whole presentation is basically to enable people at whatever path they're on -- wherever they are, what's the next step? How can I just move farther down whatever path I'm on? Because you can't really skip around. I find that if you skip too far ahead, that's where I got confused.
>
> You have this most amazing learning tool ever. You ever get in any problem, just ask -- "I have no idea how to put up my domain name. How do you put a website up?" All those things that were solved for you before, now you can do them yourself because it'll teach you along the way.
>
> For me, it was just spending time at each of these levels -- "I don't know how to do that. What's the next step?"

### Slide 7: Avoidance

> Step zero would be avoidance, which is a really natural inclination. It's moving really quite quickly. The main thing is to try to avoid hyping or spinning the technology, because it's going to move anyhow. You don't want to be left as a person who doesn't use the internet.
>
> There's that played-out quote: "AI is not going to take your job, but someone that uses AI will." I think it's really true, especially as you kind of -- even if you don't do the technical stuff.

---

## Section: Non-Technical Levels

### Slide 8: AI = Portal to Internet Research

> The first level is just using it for Q&A, summaries, explanations using ChatGPT. This is where prompt engineering comes into play.

_[Brief mention -- Craig moved quickly through this slide as it was foundational.]_

### Slide 9: AI as Thought Partner

> Then people are using it more like a thought partner. You can have back and forth where you're giving it information. You might drop in PDFs or docs. This is where you might try different models and see that some models have different personalities. The three main ones obviously are ChatGPT, Gemini, and Claude.

_[Also discussed using web search within ChatGPT, deep research, shopping research, thinking mode, and hooking it up to notes/Gmail.]_

### Slide 11: Using AI Tools

> Wispr Flow -- are you using Wispr Flow? [...] I use it because I just don't have to decide what I'm thinking up front. I'm just thinking out loud. And I find that to be a lot faster.
>
> Other ones: Granola for meeting notes. I took all of my Apple Notes and moved them into Obsidian, which basically takes all the notes and stores them as a markdown file on your computer. So then I can put Claude Code in that directory and have it do anything I want -- take all the recipes I've ever had and categorize them, tag them. It can take all my holiday letters and look at things I've written. It can look at all my notes for all the negotiation clients I've had and look at the commonalities.
>
> I'm still barely scratching the surface here.

### Slide 10: Context Management

> At any given time, you're just taking a bunch of written information, chopping it into bits -- into tokens -- and then putting it through a black box, and the black box spits out other tokens.
>
> Learning to use structured input -- most people don't know what Markdown is. Learning to use Markdown, learning to use YAML to give it structured input. A lot of people don't understand that if you give it a PDF, that is way worse than giving it a markdown file.
>
> This is the level where you start to have results feeling reliable. Before that, you're like, "the model is not very good" or "I tried this thing but it didn't really do it." Or it started giving crap answers because you didn't realize your context window is super long now and it's forgotten the stuff you thought it had initially.

### Slide 12: AI-Powered Browsing

> I think about the browser as the modern workbench. I used Atlas for a while -- this is ChatGPT's Atlas, which is not a Chrome extension, it's actually like a fork of Chrome. It acts just like Chrome, gives you Chrome extensions and stuff.
>
> But this stuff is wicked. If you go to a site and you're like, "I don't really understand these things," this little thing right here pulls in the whole page. This blue line -- this is now all in context, the whole page. So now I can just be like, "explain this to me like I'm in high school."
>
> And this is all built into Chrome. It's just in settings -- AI -- and you can enable it. This thing just by itself is a huge unlock because now anything you ever see on a website, you never have to be confused. And you don't have to do copy and paste. You're just kind of like, "I don't understand that."

_[Craig demonstrated the Gemini sidebar in Chrome live during the conversation.]_

### Slide 13: Creating Media with AI

> There's different models. Using Midjourney is a whole hop because you have to use Discord. ChatGPT is built in. Nano Banana -- some people have used it, some haven't.
>
> The thing that I think is interesting is that most people use it as a curiosity -- "oh, create this image." I think the skill here is: can you get it to give you what you actually want? That is a couple of hops further than just saying "I've used it and it's kind of interesting." You have to learn about camera angles and other stuff. Or you don't learn about it -- you just say, "Hey, I have this idea. Teach me what I need to know" and then have it write the script for you.
>
> So much of this is about: can you pop back out to one more level? It's like, I don't ask "I need to learn the thing." I ask, "How do you learn that thing? Tell me what I need to know, and then have me correct."

### Slide 14: AI for Automation

> I don't know if you got into the N8N stuff. [...] I actually think that doing it the way you initially do with N8N is so slow compared to just having Claude Code do it for you. Like Claude Code can do everything and more and you don't even have to worry about this stuff. You're just telling it the inputs and the outputs.
>
> But if you want a visual interface, I think for a non-technical person, this is a huge unlock.

### Slide 15: Natural Language Software Tools

> Then you get to natural language tools, which are like Lovable, Bolt, Google AI Studio. These things are great for prototyping and they give you a sense.
>
> So this is Gemini -- it's got a preview mode and a code mode. I can look here and just see it start to create things. It's basically a chat interface and it's creating a website. I gave it almost nothing, so it's just going to one-shot it.
>
> In my opinion, there's no reason to ever use Squarespace at this point. It's getting to the point where there's not a whole lot of reasons to use a lot of things.
>
> This is almost the last stop on the completely non-technical thing.

_[Craig demonstrated Google AI Studio live, showing it generating a landing page in real-time.]_

### Slide 15b: Claude Co-work

> Claude Co-work is the newest installment of "hey, can we take what developers are doing and make it into a GUI interface?" I was using it on this presentation.
>
> What it allows you to do is give it access to a folder -- I give it access to the talk slides folder where this development stuff is. Co-work does better when it's not doing coding stuff. There's no point in doing that. What you need is to give it a folder like "organize files" and then it's going to make decisions about the files. It's going to take my downloads file and scan and propose a whole bunch of stuff and then go ahead.

---

## Section: Technical Levels

### Slide 16: Command Line Interface (CLI)

> Now we're at the point where, okay, if you want to learn how to actually do work as opposed to just get information, I think most stuff is happening in the command line interface. All the tools that you need are CLI tools -- Claude Code is a CLI tool, Gemini, Codex is CLI.
>
> This is where it starts scaring people. For example, I'm using Ghostty. Upgrading to Ghostty -- huge upgrade. It's kind of like Terminal is basically Safari. This is like Chrome -- the tabs make a huge difference. You can customize it. I can split screens, have a whole bunch going at the same time.

_[Craig showed his Ghostty terminal setup with multiple panes/tabs running different projects.]_

### Projects Walkthrough

_[At this point, Craig walked through the various projects he's built as demonstrations of what's possible:]_

**CraigDosSantos.com:**

> The first one was my homepage. I hadn't rolled my own homepage since maybe the early 2000s. One of the things I did was I wrote an automation to scrape all my old website posts -- this goes back to the early 2000s. I went to Web Archive and pulled all the stuff I don't have access to anymore, collated it, turned it into a markdown file, cleaned it up, and pulled it onto my website. That was an impossible task before. That was an example of using Claude Code for automation.

**The Secret Game:**

> This is basically like a version of secrets. You choose a question, answer it, and then it anonymizes your answer. You take a URL, drop it into a WhatsApp group, and anyone can answer the question -- but you only see the answers if you've answered yourself. What I was working on was: can I create a web app that has a persistent back end, has authentication, has the idea of creating different rooms with persistent state? This was way beyond my ability level as a developer.

**Freestyle Flow:**

> _(Brief mention -- shown previously.)_

**OurWeUnion (wedding site):**

> I did it initially in Google AI Studio to see how that worked, then modified it in Claude Code. It's worked -- it's been flawless. People are RSVPing into our Google Sheet. It's calling Google APIs.

**Dialogue Dojo:**

> I wanted to create a voice-to-voice. You give it problems and it acts as a conversational partner and you practice -- like active listening. And then it gives you feedback on what you say.

_[Craig demonstrated live -- the app said "Hey, is this a good time to chat?" and began a practice scenario.]_

**Instant Book:**

> This takes in an EPUB. I can go to any part of the book and get a summary, get key points. This lets me zoom in and zoom out. When I created this, I was kind of early in using Claude Code. I would do it completely differently now.

**YouTube Summary:**

> If you drop a URL in there -- this is a video about the creator of Claude Code explaining his setup. I want the ability to quickly look at what it is. It gives me hotlinks, takeaways. Even videos I've seen before, I put in here and come back to be like, "what was that one thing again?"
>
> It creates a blog post -- formats it like something I want to read with all the information in it. I can switch into transcript mode. I can use Gemini to ask questions about it.
>
> The other cool thing is I can say, "Here are 45 videos about freestyling." I check all these boxes and it loads all three transcripts. Now I can look at multiple videos at the same time. This has been super useful for staying up on things way faster than surfing YouTube.

**Video Sum (Mac app):**

> I have tons of classes. I want to go through notes from them, or I didn't take notes. I have the video, but you can't drop the video into chat. Also, doing it in the cloud is actually quite expensive. So this runs locally as a Mac app.
>
> The back end splits the audio file using FFmpeg, then feeds it in chunks to Whisper. If it's a two-hour thing, you can't feed it all at once. It runs locally on my machine, so it's not costing a lot of money. Then I use Claude through API usage to create all the artifacts.

**Quota:**

> This is the one I'm working on the most. The problem was: if I wanted to launch my YouTube summary page or the book site, am I going to create subscriptions for each one? It doesn't make sense.
>
> Quota is about: can you offer something to users and have them not have to put in an API key? They just put in five bucks and it's no longer like "I have to have a $10 subscription."

**Slide Image Creation Process:**

> When I'm choosing images for this presentation -- I didn't go to Nano Banana every time. I created a script that went through my talk slides and said "come up with six options." It did all six options.
>
> The character -- it wasn't perfect, but I gave it the idea of the character and said "keep the character similar." Nano Banana's Pro model is actually much better at this.
>
> I created an app where I click and then give feedback -- "I don't like variation five because it has an X through it, but everything else is great." Then I copy the JSON response and drop it in Claude Code with all my feedback.
>
> Essentially, in one of the terminal windows, I have it working on the React Flow slide deck -- all the widgets, the metro map. And then mainly I'm like, "I need to work on the actual slides themselves." I spoke all my ideas out, had it create the outline. Then I feed it the markdown outline and say, "I need to create images -- create me a website that lets me choose and give feedback." Then "run and give me options for each slide."
>
> The slides are being created by code that's calling Nano Banana, creating the website, and creating the feedback mechanism. All I'm doing is making decisions.

_[Discussion about meta-level thinking -- using AI to build tools that help you use AI more effectively.]_

---

### Slide 18: Using Git and GitHub

> Using Git and GitHub -- how much are you using GitHub now? [...] I would say this is a big unlock. You should spend time on it because it actually took me a while. I thought I understood what it was. I'd used it before. But it actually is fairly complicated.
>
> Looking at where the head is, where it's branched off, how what's merged, PRs and everything -- it was not super intuitive for me. But once you really unlock this, now you're pulling projects from other people. And that is a huge thing.
>
> When people talk about Claude Bot, for example, they released the entire thing on GitHub. Whenever you have some open source project, you can take it -- with Claude Code now, it's so great because you take the project, there's a README file, and then you can have it explain what's happening in different parts. Like, "I want this project, but I don't want these parts." Or pulling people's Claude MD files or their plugins or their command line stuff.
>
> It's the difference between writing books on your own and having access to all the library books everybody's written.

### Slide 19: Agents and AI Coding

> I think you should probably move beyond Cursor eventually. Cursor is cool as the intro, entry level. But it's questionable what their value is because they don't have their own models. They're modifying other people's models -- they're definitely not training their own stuff.
>
> Google's Anti-Gravity is an easy place to start for people who don't code. It has this thing called the Agent Manager. This is a coding window -- same as VS Code or Cursor. But here, there's no code. You're just talking to it. You can pull out and have a whole bunch of projects going at once.
>
> You're just talking to it and it never even shows you the code. Which is interesting for somebody who doesn't want to look at a terminal.

_[Craig demonstrated Google's Anti-Gravity IDE and its agent manager panel.]_

### Slide 20: Modes and Workflows

> You're really looking at your modes -- planning mode, research agent, development mode, code review mode. Each one of those are different modes you can put Claude Code in.
>
> The modes are basically different context and requirements for different outputs. The nice thing about planning mode is that it'll ask you a bunch of questions. And there are certain plugins that force it to ask a bunch of questions to clarify things. That's really helpful.
>
> If you're going to release something, it's one thing to just whack around. But if you're going to release something, you need to plan, build, test, review, deploy, check for bugs in the deployment, and refactor things -- because things get super messy.

_[Discussion about meta-level thinking:]_

> At every layer of this, you're thinking: how can I just be making decisions and not getting stuck in learning this thing? Have it teach me. If I need understanding to make decisions, I should learn it -- but have it teach me. If it's about me learning so I could do it, then I should just have it do it.

### Slide 20b: Meta Level Meta Thinking

_[Covered inline during the Modes and Workflows discussion above.]_

### Slide 21: Using AI to Go Live

> Having it go live is a whole set of things. Are you going to use Vercel?
>
> Vercel is a serverless deployment. You can host things. It doesn't allow you to use databases inherently, but it hooks up with Supabase super easy. In the old school days, you'd have your own server with physical rack space. Then you could launch with AWS or cloud services. Vercel has just made deployment easier -- because deployment is actually a pain because you're going from running it on your machine to running it on a different machine with different packages and infrastructure.
>
> Is it used at high level? Vercel is legit. Facebook's not using Vercel, but you can definitely launch a real product using it.
>
> The cool part is all these tools have CLI tools. So you can have Claude Code be like, "Instead of me going to Vercel, just use the Vercel CLI and set it up for me." Same thing with Supabase -- it'll make you authenticate and everything. You can get it to do almost everything.
>
> I use Cloudflare for domains and DNS. Everyone uses Cloudflare -- they don't necessarily use it for hosting domains. I like having it all in one spot, and Cloudflare has great security and a lot of free stuff.

### Slide 22: Customizing the Harness

> Customizing the harness -- slash commands, sub-agents, these things are changing constantly. They just launched tasks, which are like a markdown to-do file. Tasks are stored at your user level, so you can have multiple Claude instances all look at the same task list and go off and do tasks.
>
> It used to be that you'd have to make your own agents. There was this thing called Beads -- a third-party person created it. It was basically a memory system for multiple sessions. Eventually Anthropic was like, "that's a good idea, we'll do it."
>
> Working on your Claude MD file for each project so it's actually relevant. Sub-agents are specialized versions of the agent. I'll do something like "launch three different code reviewers that each have different personalities in terms of what they're looking for. Rank the results and give me a summary of what they all agree on."
>
> Hooks -- not web hooks, those are different. There are a bunch of times when you can slot in a hook. You can say, "Every time I run a command, when it's done, run these things" -- like a post-run-tool hook. Or "When I ask to run a command, check to make sure it's not one of these commands that's going to delete my hard drive."
>
> Skills are probably the biggest area of growth right now. A skill is basically just a folder with markdown files. They're loaded up at the moment they're needed. Like Neo in The Matrix -- you don't permanently load them. The AI loads skills when needed. You can say, "Every time I say 'do research,' use the research skill." And then it'll know to look at Reddit as a source, or run a Python automation as part of the skill.
>
> You're like one markdown file away from a lot of crazy things. There's one called Skill Creator -- everybody should have it because it lets you create new skills. Meta-level thinking again.
>
> Customizing the harness is a huge thing -- both meta-level thinking and customizing the harness is the difference between being a 1x engineer and a 10x engineer.

### Slide 23: Context Engineering

> Context engineering -- I feel like this is a constant thing. You're trying to figure out how to make sure you don't have too much context and it's only relevant to what you need. For certain things you want to spin up sub-agents.
>
> The difference with a sub-agent is: if you've used 40% of your context and then you use a sub-agent, the sub-agent has its own context window. It goes and does a task and then just comes back with the answer. So using them lets you do a lot of things in parallel where it would otherwise use up all of your context.
>
> Getting better at context engineering is kind of the whole game right now.

### Slide 24: Parallel Agents and Sub-agent Orchestration

> I used Conductor.build for a while. Beads is the memory management thing I was mentioning.
>
> The whole point here is that you are now not chatting back and forth. You're planning, you say "tell me what the outputs should be," you feed it as much context as you need, and it just goes. You come back in 20 minutes and it's done.

### Slide 25: Swarms and Infrastructure

> This is very tip of the spear. Running coding agents in a virtual private server. Now you're no longer running Claude Code on your machine. You are renting a server and running Claude Code on there.
>
> You're running three or four or five agents in parallel. You're shoveling all the instructions you can and saying, "Cool, I'm going out. Come back tomorrow morning. Let's see what you got done."
>
> You're talking about around $50 for the server, $100-200 for the Claude max plan. I'm on the Max plan. You can get the 5x max for $200. And then you probably want Codex as well. Gemini is doing pretty well right now. You might be doing all three in parallel -- code it and see "tell me what you guys agreed on."
>
> For 500 bucks -- that's 10x cheaper than one really, really, really cheap abroad engineer.
>
> _[Reference to Ralph Wiggum setup -- GitHub open source project for running agents on VPS.]_
> This guy open sourced how he does this and created a wizard to help you set it up. The tool is free -- you pay for the hosting services. "Your developer costs $5,000 a month. For under $700, you get 10+ AI agents working 24/7 writing code."

---

## Section: Closing

### Slide 26: The Only Way Forward Is Through

> I'm not making any money off the stuff yet because I'm still learning. But I'm on the edge of that changing. I'll try something -- whether I'm successful or not is a whole other concept. But I'm already past the point where, for example, this presentation tool -- I think I could sell this kind of site.

_[The conversation transitioned into informal discussion about NFC chips, project ideas, and other tangential topics.]_

---

## Notes

- This was a casual, conversational walkthrough -- not a formal presentation delivery. Craig was sitting with a friend, showing slides and demonstrating tools live.
- Several tangential conversations occurred (about NFC chips, a friend named Denise, dog "Bob" stopping by for kisses, etc.) that have been excluded.
- Craig frequently demonstrated tools live -- Gemini sidebar in Chrome, Google AI Studio, Anti-Gravity, his YouTube Summary app, Dialogue Dojo voice app, and his slide image creation workflow.
- The friend in the conversation appeared to be someone who uses Claude Code / Cursor but hadn't gone deep into GitHub, deployment, or harness customization yet.
